{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9284512d-f54b-45ac-a73d-ad35969d623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Training pairs: 13519 | Validation pairs: 1503\n",
      "\n",
      "--- Running SMALL model ---\n",
      "\n",
      "=== Running full pipeline for TrOCR SMALL ===\n",
      "Memory cleaned up\n",
      "\n",
      "===== System Resource Check =====\n",
      "Model: microsoft/trocr-small-handwritten\n",
      "Free Disk Space: 21.35 GB (Need: 0.59 GB)\n",
      "GPU: NVIDIA A40\n",
      "GPU Memory: 45416.12 MB (Need: 1200.00 MB)\n",
      "Disk Space: SUFFICIENT\n",
      "GPU Memory: SUFFICIENT\n",
      "Loading processor and model: microsoft/trocr-small-handwritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "[Epoch 1] Train Loss: 0.5513 | Val Loss: 0.0709\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 2/15\n",
      "[Epoch 2] Train Loss: 0.0694 | Val Loss: 0.0608\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 3/15\n",
      "[Epoch 3] Train Loss: 0.0478 | Val Loss: 0.0391\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 4/15\n",
      "[Epoch 4] Train Loss: 0.0303 | Val Loss: 0.0295\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 5/15\n",
      "[Epoch 5] Train Loss: 0.0212 | Val Loss: 0.0245\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 6/15\n",
      "[Epoch 6] Train Loss: 0.0155 | Val Loss: 0.0239\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 7/15\n",
      "[Epoch 7] Train Loss: 0.0116 | Val Loss: 0.0208\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 8/15\n",
      "[Epoch 8] Train Loss: 0.0082 | Val Loss: 0.0208\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 9/15\n",
      "[Epoch 9] Train Loss: 0.0057 | Val Loss: 0.0203\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 10/15\n",
      "[Epoch 10] Train Loss: 0.0037 | Val Loss: 0.0201\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 11/15\n",
      "[Epoch 11] Train Loss: 0.0024 | Val Loss: 0.0187\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 12/15\n",
      "[Epoch 12] Train Loss: 0.0014 | Val Loss: 0.0191\n",
      "\n",
      "Epoch 13/15\n",
      "[Epoch 13] Train Loss: 0.0008 | Val Loss: 0.0185\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 14/15\n",
      "[Epoch 14] Train Loss: 0.0005 | Val Loss: 0.0180\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 15/15\n",
      "[Epoch 15] Train Loss: 0.0003 | Val Loss: 0.0181\n",
      "** Final model saved! **\n",
      "Memory cleaned up\n",
      "Loaded 10475 test image-text pairs\n",
      "Loading model from trocr_balinese_small_best\n",
      "Loading processor from microsoft/trocr-small-handwritten\n",
      "\n",
      "Test CER for trocr_balinese_small_best: 0.1563\n",
      "\n",
      "=== Top 5 Worst Samples by CER ===\n",
      "1) Image: test4934.png\n",
      "   CER: 11.0000\n",
      "   Predicted    : carik-agung\n",
      "   Ground Truth : .\n",
      "\n",
      "2) Image: test1330.png\n",
      "   CER: 10.0000\n",
      "   Predicted    : mangkusana\n",
      "   Ground Truth : .\n",
      "\n",
      "3) Image: test10070.png\n",
      "   CER: 9.0000\n",
      "   Predicted    : ngebapnia\n",
      "   Ground Truth : .\n",
      "\n",
      "4) Image: test858.png\n",
      "   CER: 5.0000\n",
      "   Predicted    : apang\n",
      "   Ground Truth : .\n",
      "\n",
      "5) Image: test1279.png\n",
      "   CER: 5.0000\n",
      "   Predicted    : tuang\n",
      "   Ground Truth : 0\n",
      "\n",
      "Logged trocr_balinese_small_best: 0.1563\n",
      "Memory cleared after testing\n",
      "Final Test CER for SMALL: 0.1563\n",
      "Memory cleaned up\n",
      "\n",
      "--- Running BASE model ---\n",
      "\n",
      "=== Running full pipeline for TrOCR BASE ===\n",
      "Memory cleaned up\n",
      "\n",
      "===== System Resource Check =====\n",
      "Model: microsoft/trocr-base-handwritten\n",
      "Free Disk Space: 21.35 GB (Need: 1.17 GB)\n",
      "GPU: NVIDIA A40\n",
      "GPU Memory: 45416.12 MB (Need: 2400.00 MB)\n",
      "Disk Space: SUFFICIENT\n",
      "GPU Memory: SUFFICIENT\n",
      "Loading processor and model: microsoft/trocr-base-handwritten\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'decoder.output_projection.weight', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/15\n",
      "[Epoch 1] Train Loss: 0.2832 | Val Loss: 0.2599\n",
      "** Best model saved! **\n",
      "\n",
      "Epoch 2/15\n",
      "[Epoch 2] Train Loss: 0.1665 | Val Loss: 9.9288\n",
      "\n",
      "Epoch 3/15\n",
      "[Epoch 3] Train Loss: 0.1137 | Val Loss: 11.6090\n",
      "\n",
      "Epoch 4/15\n",
      "[Epoch 4] Train Loss: 0.1045 | Val Loss: 13.1801\n",
      "\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import editdistance\n",
    "import time\n",
    "import warnings\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "\n",
    "def check_system_resources(model_name=\"microsoft/trocr-small-handwritten\"):\n",
    "    \"\"\"\n",
    "    Check system resources to ensure we have enough space for TrOCR.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        total, used, free = shutil.disk_usage('/')\n",
    "        free_gb = free / (1024**3)  # Convert bytes to GB\n",
    "        estimated_size_mb = {\"small\": 300, \"base\": 600, \"large\": 1200}\n",
    "        if \"small\" in model_name.lower():\n",
    "            size_category = \"small\"\n",
    "        elif \"base\" in model_name.lower():\n",
    "            size_category = \"base\"\n",
    "        else:\n",
    "            size_category = \"large\"\n",
    "        model_size_mb = estimated_size_mb.get(size_category, 300)\n",
    "        model_size_gb = model_size_mb / 1024\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_info = torch.cuda.get_device_properties(0)\n",
    "            gpu_name = gpu_info.name\n",
    "            total_gpu_memory_mb = gpu_info.total_memory / (1024 * 1024)\n",
    "            torch.cuda.empty_cache()\n",
    "            free_gpu_memory_mb = torch.cuda.memory_reserved(0) / (1024 * 1024)\n",
    "            required_gpu_mb = model_size_mb * 4  \n",
    "        else:\n",
    "            gpu_name = \"No GPU detected\"\n",
    "            total_gpu_memory_mb = 0\n",
    "            free_gpu_memory_mb = 0\n",
    "            required_gpu_mb = model_size_mb * 3\n",
    "        disk_sufficient = free_gb > (model_size_gb * 2)\n",
    "        gpu_sufficient = (total_gpu_memory_mb > required_gpu_mb) if torch.cuda.is_available() else False\n",
    "        resources = {\n",
    "            \"free_disk_gb\": free_gb,\n",
    "            \"required_disk_gb\": model_size_gb * 2,\n",
    "            \"disk_sufficient\": disk_sufficient,\n",
    "            \"gpu_name\": gpu_name,\n",
    "            \"total_gpu_memory_mb\": total_gpu_memory_mb,\n",
    "            \"required_gpu_mb\": required_gpu_mb,\n",
    "            \"gpu_sufficient\": gpu_sufficient\n",
    "        }\n",
    "        print(\"\\n===== System Resource Check =====\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "        print(f\"Free Disk Space: {free_gb:.2f} GB (Need: {model_size_gb * 2:.2f} GB)\")\n",
    "        print(f\"GPU: {gpu_name}\")\n",
    "        print(f\"GPU Memory: {total_gpu_memory_mb:.2f} MB (Need: {required_gpu_mb:.2f} MB)\")\n",
    "        print(f\"Disk Space: {'SUFFICIENT' if disk_sufficient else 'INSUFFICIENT'}\")\n",
    "        print(f\"GPU Memory: {'SUFFICIENT' if gpu_sufficient else 'INSUFFICIENT'}\")\n",
    "        if not disk_sufficient or not gpu_sufficient:\n",
    "            print(\"\\WARNING: System resources may be insufficient for TrOCR model\")\n",
    "            if not disk_sufficient:\n",
    "                print(f\"  - Need {model_size_gb * 2:.2f} GB disk space, but only have {free_gb:.2f} GB\")\n",
    "            if not gpu_sufficient and torch.cuda.is_available():\n",
    "                print(f\"  - Need {required_gpu_mb:.2f} MB GPU memory, but only have {total_gpu_memory_mb:.2f} MB\")\n",
    "        return resources\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking system resources: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def cleanup():\n",
    "    \"\"\"Clean up memory and GPU cache.\"\"\"\n",
    "    for var in ['model', 'processor', 'tokenizer', 'feature_extractor']:\n",
    "        if var in globals():\n",
    "            del globals()[var]\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Memory cleaned up\")\n",
    "\n",
    "\n",
    "# Global device setting\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# File paths (adjust as needed)\n",
    "base_dir = os.getcwd()\n",
    "train_ground_truth_path = os.path.join(base_dir, 'balinese_transliteration_train.txt')\n",
    "train_images_dir = os.path.join(base_dir, 'balinese_word_train')\n",
    "test_ground_truth_path = os.path.join(base_dir, 'balinese_transliteration_test.txt')\n",
    "test_images_dir = os.path.join(base_dir, 'balinese_word_test')\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a file with the format: filename;label.\n",
    "    Converts text labels to lowercase.\n",
    "    \"\"\"\n",
    "    filenames, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split(\";\")\n",
    "                if len(parts) == 2:\n",
    "                    img, label = parts\n",
    "                    label = label.lower()\n",
    "                    filenames.append(img)\n",
    "                    labels.append(label.lower())\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line}\")\n",
    "    return pd.DataFrame({\"filename\": filenames, \"label\": labels})\n",
    "\n",
    "\n",
    "# Load training data and split into train/validation sets.\n",
    "data = load_data(train_ground_truth_path)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train_data, val_data = train_data.reset_index(drop=True), val_data.reset_index(drop=True)\n",
    "print(f\"Training pairs: {len(train_data)} | Validation pairs: {len(val_data)}\")\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Stack pixel values and labels from the batch.\"\"\"\n",
    "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])\n",
    "    labels = torch.stack([item[\"labels\"] for item in batch])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "\n",
    "class BalineseOCRDataset(Dataset):\n",
    "    def __init__(self, df, images_dir, processor, max_target_length=128):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.images_dir, row[\"filename\"])\n",
    "        label = row[\"label\"]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        encoding = self.processor(\n",
    "            images=image,\n",
    "            text=label,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        return encoding\n",
    "\n",
    "\n",
    "def setup_trocr(model_name=\"microsoft/trocr-small-handwritten\"):\n",
    "    \"\"\"\n",
    "    Set up the TrOCR model and processor.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "        print(f\"Loading processor and model: {model_name}\")\n",
    "        processor = TrOCRProcessor.from_pretrained(model_name)\n",
    "        model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "        model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "        model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "        model.config.vocab_size = model.config.decoder.vocab_size\n",
    "        model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "        model.config.max_length = 64\n",
    "        model.config.early_stopping = True\n",
    "        model.config.no_repeat_ngram_size = 3\n",
    "        model.config.length_penalty = 2.0\n",
    "        model.config.num_beams = 4\n",
    "        return model, processor\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up TrOCR: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "def create_dataloaders(processor, batch_sizes=(16, 32)):\n",
    "    \"\"\"\n",
    "    Create DataLoaders for training and validation.\n",
    "    \"\"\"\n",
    "    train_dataset = BalineseOCRDataset(train_data, train_images_dir, processor)\n",
    "    val_dataset = BalineseOCRDataset(val_data, train_images_dir, processor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_sizes[0], shuffle=True,\n",
    "                              num_workers=2, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_sizes[1], shuffle=False,\n",
    "                            num_workers=2, collate_fn=collate_fn)\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def train_trocr(model, processor, train_loader, val_loader, num_epochs=3, save_path=\"trocr_model\"):\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    num_training_steps = len(train_loader) * num_epochs\n",
    "    num_warmup_steps = num_training_steps // 10\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,\n",
    "                                                  num_training_steps=num_training_steps)\n",
    "    best_val_loss = float(\"inf\")\n",
    "    training_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_train_loss += loss.item()\n",
    "            # if (step + 1) % 100 == 0:\n",
    "                # print(f\"Step {step+1}: Loss = {loss.item():.4f}\")\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        training_losses.append(avg_train_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        total_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                pixel_values = batch[\"pixel_values\"].to(device)\n",
    "                labels = batch[\"labels\"].to(device)\n",
    "                outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "                total_val_loss += outputs.loss.item()\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        validation_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            model.save_pretrained(f\"{save_path}_best\")\n",
    "            processor.save_pretrained(f\"{save_path}_best\")\n",
    "            print(\"** Best model saved! **\")\n",
    "    \n",
    "    model.save_pretrained(save_path)\n",
    "    processor.save_pretrained(save_path)\n",
    "    print(\"** Final model saved! **\")\n",
    "    return model, processor, training_losses, validation_losses\n",
    "\n",
    "\n",
    "def calculate_global_cer(results):\n",
    "    total_ed, total_refs = 0, 0\n",
    "    for r in results:\n",
    "        ref = r['ground_truth_caption']\n",
    "        hyp = r['predicted_caption']\n",
    "        total_ed += editdistance.eval(ref, hyp)\n",
    "        total_refs += len(ref)\n",
    "    return total_ed / total_refs if total_refs > 0 else 0.0\n",
    "\n",
    "\n",
    "def print_top_worst_samples(results, n=5):\n",
    "    results_with_cer = []\n",
    "    for r in results:\n",
    "        ref = r['ground_truth_caption']\n",
    "        hyp = r['predicted_caption']\n",
    "        cer = editdistance.eval(ref, hyp) / (len(ref) if len(ref) > 0 else 1)\n",
    "        new_r = r.copy()\n",
    "        new_r['cer'] = cer\n",
    "        results_with_cer.append(new_r)\n",
    "    results_with_cer.sort(key=lambda x: x['cer'], reverse=True)\n",
    "    worst_samples = results_with_cer[:n]\n",
    "    print(f\"\\n=== Top {n} Worst Samples by CER ===\")\n",
    "    for i, sample in enumerate(worst_samples, start=1):\n",
    "        print(f\"{i}) Image: {sample['image_filename']}\")\n",
    "        print(f\"   CER: {sample['cer']:.4f}\")\n",
    "        print(f\"   Predicted    : {sample['predicted_caption']}\")\n",
    "        print(f\"   Ground Truth : {sample['ground_truth_caption']}\\n\")\n",
    "\n",
    "\n",
    "csv_file = \"test_cer_results.csv\"\n",
    "\n",
    "def log_test_cer(model_name, cer_value):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        df = pd.DataFrame(columns=[\"model_name\", \"test_cer\"])\n",
    "    if model_name in df['model_name'].values:\n",
    "        df.loc[df['model_name'] == model_name, 'test_cer'] = cer_value\n",
    "    else:\n",
    "        new_row = pd.DataFrame({\"model_name\": [model_name], \"test_cer\": [cer_value]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Logged {model_name}: {cer_value:.4f}\")\n",
    "\n",
    "\n",
    "def test_trocr_model(model_path=\"trocr_balinese_best\", processor_path=None):\n",
    "    \"\"\"\n",
    "    Test a trained TrOCR model on test data.\n",
    "    \"\"\"\n",
    "    from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "    if processor_path is None:\n",
    "        processor_path = \"microsoft/trocr-small-handwritten\"\n",
    "    test_filenames, test_labels = [], []\n",
    "    with open(test_ground_truth_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split(';')\n",
    "                if len(parts) == 2:\n",
    "                    filename, label = parts\n",
    "                    test_filenames.append(filename)\n",
    "                    test_labels.append(label.lower())\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line}\")\n",
    "    test_data = pd.DataFrame({\"filename\": test_filenames, \"label\": test_labels})\n",
    "    print(f\"Loaded {len(test_data)} test image-text pairs\")\n",
    "    try:\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "        print(f\"Loading processor from {processor_path}\")\n",
    "        processor = TrOCRProcessor.from_pretrained(processor_path)\n",
    "        model = model.to(device)\n",
    "        results = []\n",
    "        batch_size = 16\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_data), batch_size):\n",
    "                batch_data = test_data.iloc[i:i+batch_size]\n",
    "                images = []\n",
    "                for idx, row in batch_data.iterrows():\n",
    "                    img_path = os.path.join(test_images_dir, row['filename'])\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    images.append(image)\n",
    "                pixel_values = processor.image_processor(images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "                generated_ids = model.generate(pixel_values)\n",
    "                predictions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                for (_, row), pred in zip(batch_data.iterrows(), predictions):\n",
    "                    results.append({\n",
    "                        'image_filename': row['filename'],\n",
    "                        'predicted_caption': pred,\n",
    "                        'ground_truth_caption': row['label']\n",
    "                    })\n",
    "        cer = calculate_global_cer(results)\n",
    "        print(f\"\\nTest CER for {model_path}: {cer:.4f}\")\n",
    "        print_top_worst_samples(results, n=5)\n",
    "        model_name_only = os.path.basename(model_path)\n",
    "        log_test_cer(model_name_only, cer)\n",
    "        return cer, results\n",
    "    except Exception as e:\n",
    "        print(f\"Error testing TrOCR model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    finally:\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if 'processor' in locals():\n",
    "            del processor\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Memory cleared after testing\")\n",
    "\n",
    "\n",
    "def run_full_pipeline(model_variant=\"small\", num_epochs=3, batch_size=8):\n",
    "    if model_variant == \"small\":\n",
    "        hf_model = \"microsoft/trocr-small-handwritten\"\n",
    "        save_path = \"trocr_balinese_small_best\"\n",
    "        proc_path = \"microsoft/trocr-small-handwritten\"\n",
    "    elif model_variant == \"base\":\n",
    "        hf_model = \"microsoft/trocr-base-handwritten\"\n",
    "        save_path = \"trocr_balinese_base_best\"\n",
    "        proc_path = \"microsoft/trocr-base-handwritten\"\n",
    "    else:\n",
    "        hf_model = \"microsoft/trocr-large-handwritten\"\n",
    "        save_path = \"trocr_balinese_large_best\"\n",
    "        proc_path = \"microsoft/trocr-large-handwritten\"\n",
    "\n",
    "    print(f\"\\n=== Running full pipeline for TrOCR {model_variant.upper()} ===\")\n",
    "    cleanup()  # Clear memory before starting the new model run\n",
    "    check_system_resources(hf_model)\n",
    "    model, processor = setup_trocr(hf_model)\n",
    "    if model is None or processor is None:\n",
    "        raise RuntimeError(\"Model setup failed.\")\n",
    "    \n",
    "    train_loader, val_loader = create_dataloaders(processor, (batch_size, batch_size))\n",
    "    model, processor, training_losses, validation_losses = train_trocr(\n",
    "        model, processor, train_loader, val_loader, num_epochs=num_epochs, save_path=save_path\n",
    "    )\n",
    "    \n",
    "    cleanup()  # Clean up before testing\n",
    "    \n",
    "    test_cer, test_results = test_trocr_model(model_path=save_path, processor_path=proc_path)\n",
    "    return training_losses, validation_losses, test_cer, test_results\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = {}\n",
    "    for variant in [\"small\", \"base\"]:\n",
    "        print(f\"\\n--- Running {variant.upper()} model ---\")\n",
    "        train_losses, val_losses, test_cer, test_results = run_full_pipeline(model_variant=variant, num_epochs=15, batch_size=2)\n",
    "        \n",
    "        results[variant] = {\n",
    "            \"train_losses\": train_losses,\n",
    "            \"val_losses\": val_losses,\n",
    "            \"test_cer\": test_cer,\n",
    "            \"test_results\": test_results\n",
    "        }\n",
    "        \n",
    "        print(f\"Final Test CER for {variant.upper()}: {test_cer:.4f}\" if test_cer is not None else f\"Testing for {variant} failed.\")\n",
    "        cleanup()  # Clear memory after testing each model\n",
    "    \n",
    "    print(\"\\nAll models have been run. Summary of results:\")\n",
    "    for variant, res in results.items():\n",
    "        print(f\"{variant.upper()} model -> Train Losses: {res['train_losses']}, Val Losses: {res['val_losses']}, Test CER: {res['test_cer']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169b3e1f-f9e1-402f-9eca-ff2d346c58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth_path = os.path.join(base_dir, 'balinese_transliteration_test.txt')\n",
    "test_images_dir        = os.path.join(base_dir, 'balinese_word_test')\n",
    "\n",
    "test_filenames = []\n",
    "test_labels    = []\n",
    "\n",
    "def test_trocr_model(model_path=\"trocr_balinese\", processor_path=None):\n",
    "    \"\"\"\n",
    "    Test a trained TrOCR model on test data\n",
    "    \n",
    "    Args:\n",
    "        model_path: Path to the saved model\n",
    "        processor_path: Path to the processor (if different from model_path)\n",
    "    \"\"\"\n",
    "    from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "    \n",
    "    # If processor_path is not specified, try using the original processor\n",
    "    if processor_path is None:\n",
    "        processor_path = \"microsoft/trocr-small-handwritten\"\n",
    "    \n",
    "    # Load test data\n",
    "    test_filenames = []\n",
    "    test_labels = []\n",
    "    \n",
    "    with open(test_ground_truth_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split(';')\n",
    "                if len(parts) == 2:\n",
    "                    filename, label = parts\n",
    "                    label = label.lower()\n",
    "                    test_filenames.append(filename)\n",
    "                    test_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"Skipping malformed line: {line}\")\n",
    "    \n",
    "    test_data = pd.DataFrame({\n",
    "        'filename': test_filenames,\n",
    "        'label': test_labels\n",
    "    })\n",
    "    \n",
    "    print(f\"Loaded {len(test_data)} test image-text pairs\")\n",
    "    \n",
    "    try:\n",
    "        # Load model and processor (from separate paths if needed)\n",
    "        print(f\"Loading model from {model_path}\")\n",
    "        model = VisionEncoderDecoderModel.from_pretrained(model_path)\n",
    "        \n",
    "        print(f\"Loading processor from {processor_path}\")\n",
    "        processor = TrOCRProcessor.from_pretrained(processor_path)\n",
    "        \n",
    "        # Move model to device\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Results for storing predictions\n",
    "        results = []\n",
    "        batch_size = 16\n",
    "        \n",
    "        # Process test data in batches\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(test_data), batch_size):\n",
    "                batch_data = test_data.iloc[i:i+batch_size]\n",
    "                \n",
    "                # Process images\n",
    "                images = []\n",
    "                for idx, row in batch_data.iterrows():\n",
    "                    img_path = os.path.join(test_images_dir, row['filename'])\n",
    "                    image = Image.open(img_path).convert('RGB')\n",
    "                    images.append(image)\n",
    "                \n",
    "                # Get model predictions\n",
    "                pixel_values = processor.image_processor(images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "                generated_ids = model.generate(pixel_values)\n",
    "                predictions = processor.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "                \n",
    "                # Store results\n",
    "                for j, (pred, (_, row)) in enumerate(zip(predictions, batch_data.iterrows())):\n",
    "                    results.append({\n",
    "                        'image_filename': row['filename'],\n",
    "                        'predicted_caption': pred,\n",
    "                        'ground_truth_caption': row['label']\n",
    "                    })\n",
    "                \n",
    "                # print(f\"Processed {min(i+batch_size, len(test_data))}/{len(test_data)} test samples\")\n",
    "        \n",
    "        # Calculate CER\n",
    "        cer = calculate_global_cer(results)\n",
    "        print(f\"TrOCR Model Test CER: {cer:.4f}\")\n",
    "        \n",
    "        # Print worst samples\n",
    "        print_top_worst_samples(results, n=5)\n",
    "        \n",
    "        # Log to CSV\n",
    "        model_name = os.path.basename(model_path)\n",
    "        log_test_cer(model_name, cer)\n",
    "        \n",
    "        return cer, results\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error testing TrOCR model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None, None\n",
    "    finally:\n",
    "        # Clean up\n",
    "        if 'model' in locals():\n",
    "            del model\n",
    "        if 'processor' in locals():\n",
    "            del processor\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"Memory cleared\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a5c24-8aa2-4b6c-a12c-06642c6e7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_global_cer(results):\n",
    "    total_ed   = 0\n",
    "    total_refs = 0\n",
    "    for r in results:\n",
    "        ref = r['ground_truth_caption']\n",
    "        hyp = r['predicted_caption']\n",
    "        dist = editdistance.eval(ref, hyp)\n",
    "        total_ed   += dist\n",
    "        total_refs += len(ref)\n",
    "    if total_refs == 0:\n",
    "        return 0.0\n",
    "    return total_ed / total_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698f21f-b226-4413-8fca-b6091e71f8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_worst_samples(results, n=5):\n",
    "    # Calculate CER for each sample\n",
    "    results_with_cer = []\n",
    "    for r in results:\n",
    "        ref = r['ground_truth_caption']\n",
    "        hyp = r['predicted_caption']\n",
    "        dist = editdistance.eval(ref, hyp)\n",
    "        length = len(ref)\n",
    "        cer = dist / length if length > 0 else 0\n",
    "        # Copy the record and add cer\n",
    "        new_r = r.copy()\n",
    "        new_r['cer'] = cer\n",
    "        results_with_cer.append(new_r)\n",
    "\n",
    "    # Sort by CER (descending) and take the top N\n",
    "    results_with_cer.sort(key=lambda x: x['cer'], reverse=True)\n",
    "    worst_samples = results_with_cer[:n]\n",
    "\n",
    "    print(f\"\\n=== Top {n} Worst Samples by CER ===\")\n",
    "    for i, sample in enumerate(worst_samples, start=1):\n",
    "        print(f\"{i}) Image: {sample['image_filename']}\")\n",
    "        print(f\"   CER: {sample['cer']:.4f}\")\n",
    "        print(f\"   Predicted       : {sample['predicted_caption']}\")\n",
    "        print(f\"   Ground Truth    : {sample['ground_truth_caption']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411bdf1a-2736-4d84-b087-138d32f157a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = \"test_cer_results.csv\"\n",
    "\n",
    "def log_test_cer(model_name, cer_value):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Check if model_name exists\n",
    "    if model_name in df['model_name'].values:\n",
    "        # Update existing row\n",
    "        df.loc[df['model_name'] == model_name, 'test_cer'] = cer_value\n",
    "    else:\n",
    "        # Add new row - use concat instead of append\n",
    "        new_row = pd.DataFrame({\"model_name\": [model_name], \"test_cer\": [cer_value]})\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"Logged {model_name}: {cer_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c69e9b-b9b8-4fa8-9649-92e42655d53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer, results = test_trocr_model(\"trocr_balinese_best\", \"microsoft/trocr-small-handwritten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734ddbf-dd33-4519-bbd8-8977a3fe25e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
